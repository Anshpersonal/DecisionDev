# This is the default values to run Ollama localy. 
LLM_TYPE=LOCAL_OLLAMA
OLLAMA_SERVER_URL=http://host.docker.internal:11434
# Uncomment to use the IBM Granite model.
#OLLAMA_MODEL_NAME=granite3-dense:8b
#OLLAMA_MODEL_NAME=granite3-moe:3b
#OLLAMA_MODEL_NAME=mistral
OLLAMA_MODEL_NAME=llama3.2
#OLLAMA_MODEL_NAME=deepseek-r1:7b
